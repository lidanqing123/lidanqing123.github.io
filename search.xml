<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Anaconda, Conda和 Bioconda相关]]></title>
    <url>%2F2019%2F01%2F30%2FAnaconda-Conda%E5%92%8C-Bioconda%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[简介Anaconda是一个用于科学计算的Python发行版，支持 Linux, Mac, Windows系统，提供了包管理与环境管理的功能，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题。Anaconda利用工具/命令conda来进行package和environment的管理，并且已经包含了Python和相关的配套工具。 这里先解释下conda、anaconda这些概念的差别。 conda可以理解为一个工具，也是一个可执行命令，其核心功能是包管理与环境管理。包管理与pip的使用类似，环境管理则允许用户方便地安装不同版本的python并可以快速切换。 Anaconda则是一个打包的集合，里面预装好了conda、某个版本的python、众多packages、科学计算工具等等，所以也称为Python的一种发行版。其实还有Miniconda，顾名思义，它只包含最基本的内容——python与conda，以及相关的必须依赖项，对于空间要求严格的用户，Miniconda是一种选择。 conda将几乎所有的工具、第三方包都当做package对待，甚至包括python和conda自身！ Anaconda(Miniconda)安装以miniconda安装为例 1234567891011# 获取安装文件cd ~/wget https://repo.continuum.io/miniconda/Miniconda2-latest-MacOSX-x86_64.sh# 安装miniconda，根据提示完成安装cd ~/bash Miniconda2-latest-MacOSX-x86_64.sh# 需新建Terminal Session或手动加载环境变量来使得conda生效# 手动加载source ~/.bash_profie 设置国内镜像源添加清华的一系列镜像，加速下载，提高成功率。默认仓库不仅速度极慢，而且经常中断，国内镜像下载速度可达国外几百倍。 TUNA 提供了 Anaconda 仓库的镜像，运行以下命令:123conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes Conda 三方源 当前tuna还维护了一些anaconda三方源。 bioconda 添加bioconda频道，方便生物软件安装。 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ conda使用这里介绍conda常用的命令操作1234567# 查看conda版本$ conda --versionconda 4.3.30# 查看对应的python默认版本（默认环境的名字是root，注意这个root不是超级管理员的意思）$ python --versionPython 3.6.3 :: Anaconda, Inc. conda的环境管理12345678910111213141516171819202122# 创建一个名为env_test的环境，指定Python版本是2.7（conda会自动寻找2.7.x中的最新版本）$ conda create --name env_test python=2.7# 查看已安装的环境，当前被激活的环境会显示有一个星号$ conda info -e# conda environments:#env_test /home/xxxx/.conda/envs/env_testroot * /opt/anaconda3# 安装好后，使用source activate激活指定环境$ source activate env_test# 再次查看当前python版本，可以看到系统已经切换到了2.7的环境$ python --versionPython 2.7.14 :: Anaconda, Inc.# 退出当前虚拟环境，返回默认python环境$ source deactivate# 删除一个已有的环境$ conda remove --name env_test --all 包管理12345678910111213141516171819202122# 查看当前环境下已安装packages$ conda list# 查找package信息$ conda search numpy# 安装package$ conda install numpy# 安装指定版本package$ conda install numpy=1.13.3# 更新package$ conda update numpy# 删除package$ conda remove numpy另外，$ conda install Keras # 安装keras, 会顺带装上tensorflow, h5py, hdf5等$ conda install pillow # 安装PIL$ conda install opencv # 安装cv2 环境移植值得一提的是自己建立的软件环境可以很方便移植到另外一台电脑! 首先通过source activate target_env要分享的环境target_env，然后输入下面的命令会在当前工作目录下生成一个environment.yml文件 1conda env export &gt; environment.yml 小伙伴拿到environment.yml文件后，将该文件放在工作目录下，可以通过以下命令从该文件创建环境 1conda env create -f environment.yml 相关资料Anaconda 官网 bioconda 官网 Anaconda安装使用 Anaconda 镜像使用帮助| 清华大学开源镜像站 Nature Method：Bioconda解决生物软件安装的烦恼 conda与bioconda解决生信软件安装困扰]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Anaconda</tag>
        <tag>conda</tag>
        <tag>Miniconda</tag>
        <tag>Bioconda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery 学习资源]]></title>
    <url>%2F2019%2F01%2F29%2FCelery-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[使用场景在程序运行过程中，要执行一个很久的任务，但是我们又不想主程序被阻塞，常见的方法是多线程。可是当并发量过大时，多线程也会扛不住，必须要用线程池来限制并发个数，而且多线程对共享资源的使用也是很麻烦的事情。还有就是协程，但是协程毕竟还是在同一线程内执行的，如果一个任务本身就要执行很长时间，而不是因为等待IO被挂起，那其他协程照样无法得到运行。 本文要介绍一个强大的分布式任务队列Celery，它可以让任务的执行同主程序完全脱离，甚至不在同一台主机内。它通过队列来调度任务，不用担心并发量高时系统负载过大。它可以用来处理复杂系统性能问题，却又相当灵活易用。下面我们就来了解下Celery。 Celery 是什么？Celery（中文是芹菜的意思）是Python语言实现的分布式队列服务，除了支持即时任务，还支持定时任务，Celery 有5个核心角色。 记住这5个角色后面理解Celery就轻松了。 Task任务(Task)就是你要做的事情，例如一个注册流程里面有很多任务，给用户发验证邮件就是一个任务，这种耗时的任务就可以交给Celery去处理，还有一种任务是定时任务，比如每天定时统计网站的注册人数，这个也可以交给Celery周期性的处理。 BrokerBroker 的中文意思是经纪人，指为市场上买卖双方提供中介服务的人。在Celery中这个角色相当于数据结构中的队列，介于生产者和消费者之间经纪人。例如一个Web系统中，生产者是主程序，它生产任务，将任务发送给 Broker，消费者是 Worker，是专门用于执行任务的后台服务。Celery本身不提供队列服务，一般用Redis或者RabbitMQ来实现队列服务。 WorkerWorker 就是那个一直在后台执行任务的人，也成为任务的消费者，它会实时地监控队列中有没有任务，如果有就立即取出来执行。 BeatBeat 是一个定时任务调度器，它会根据配置定时将任务发送给 Broker，等待 Worker 来消费。 BackendBackend 用于保存任务的执行结果，每个任务都有返回值，比如发送邮件的服务会告诉我们有没有发送成功，这个结果就是存在Backend中，当然我们并不总是要关心任务的执行结果。 资料Celery 官网 Celery 官方文档英文版 Celery 官方文档中文版 伯乐在线 celery文章 Celery 框架学习笔记 Celery分布式任务队列快速入门 Python 并行分布式框架 Celery python之celery使用详解一 高性能异步框架Celery入坑指南 在Python中用Celery安排管理后台工作流 笔记：集群部署celery分布式任务队列]]></content>
      <tags>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker or not ?]]></title>
    <url>%2F2019%2F01%2F29%2Fdocker-or-not%2F</url>
    <content type="text"><![CDATA[在生物信息分析方面docker可以做哪些应用?在那些方面可以给我们提供便利?是否有必要转向docker? liheng大神的一段话引发了我的思考 Docker is a bless to complex systems such as the old Apache+MySQL+PHP combo, but is a curse to simple command line tools. For simple tools, it adds multiple complications (security, kernel version, Dockerfile, large package, inter-process communication, etc) with little benefit. Bioinformatics tools are not rocket science. They are supposed to be simple. If they are not simple, we should encourage better practices rather than live with the problems and resort to docker. I am particularly against dockerizing easy-to-compile tools such as velvet and bwa or well packaged tools such as spades. Another large fraction of tools in C/C++ can be compiled to statically linked binaries or shipped with necessary dynamic libraries (see salifish). While not ideal, these are still better solutions than docker. Docker will be needed for some tools with complex dependencies, but I predict most of such tools will be abandoned by users unless they are substantially better than other competitors, which rarely happens in practice.]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用网站收集]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[流程脚本语言nextflow github网址 Nextflow’s documentation! 强大的生物信息流程定制工具nextflow 初识Nextflow (系列之一) Nextflow的基本认知(系列之二) NextFlow的步骤Process(系列之三) Nextflow实践中遇到的问题(系列之四) Getting Started with Nextflow Snakemake Snakemake Tutorial snakemake使用笔记 CWL Common Workflow Language Getting Started with CWL WDL User Guide Getting Started with WDL WDL入门 WDL学习 GATK官方推荐的workflow语言-WDL 比较 Snakemake vs. Nextflow: strengths and weaknesses workflow management system : WDL, CWL, Ruffus, SnakeMake, etc 资讯 华大基因举办第二届基因组云计算技术开发者大会 DockstoreDockstore, developed by the Cancer Genome Collaboratory, is an open platform used by the GA4GH for sharing Docker-based tools described with the Common Workflow Language (CWL), the Workflow Description Language (WDL), or Nextflow (NFL) Documentation Best Practices HEXO Hexo 中文官方文档 如何优雅地发布Hexo博客 Markdown Markdown 语法说明]]></content>
      <categories>
        <category>收集器</category>
      </categories>
      <tags>
        <tag>网址</tag>
        <tag>nextflow</tag>
        <tag>Snakemake</tag>
        <tag>CWL</tag>
        <tag>WDL</tag>
        <tag>Dockstore</tag>
        <tag>hexo</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
